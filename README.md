# MLOps Predictive Maintenance

This project builds an end-to-end **machine failure prediction pipeline** using real-world sensor data, following **MLOps best practices** such as data versioning, reproducible pipelines, and experiment tracking.

---

## ğŸ“Œ Objective

The goal is to predict **machine failure events** using historical sensor readings and temporal patterns, while structuring the workflow in a way that reflects **real production ML systems**, not just a notebook-level ML experiment.

---

## ğŸ“Š Dataset

- Source: Predictive maintenance sensor dataset  
- Contains:
  - Date of observation  
  - Device identifier  
  - Binary failure label  
  - Multiple sensor metrics (`metric1` â†’ `metric9`)  

The dataset is tracked using **DVC** instead of Git to ensure:
- reproducibility  
- scalability  
- proper data version control  

---
### ğŸ“‚ Project Structure

```text
mlops-predictive-maintenance/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                # Dataset tracked with DVC
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda.ipynb           # Exploratory analysis
â”œâ”€â”€ .dvc/                   # DVC metadata
â”œâ”€â”€ .dvcignore
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ” Exploratory Data Analysis (EDA)

EDA focused on understanding **temporal behavior** and **sensor relationships** before model training.

### Key findings

#### 1. Temporal patterns
- Failure frequency varies across **months** and **weekdays**.
- Peaks align with **high operational workload periods** and drop toward **weekends**, suggesting workload influence rather than random degradation.

#### 2. Sensor behavior
- Certain sensor metrics show **distributional differences** between failure events and normal operation.
- Strong **multicollinearity** detected between:
  - `metric7` and `metric8`  
  â†’ To avoid:
    1. redundant information
    2. unstable model coefficients
    3. inflated variance
    
    metric8 will be removed during modeling.

#### 3. Correlation structure
- Most sensors are exhibit weak pairwise correlation.
- A few moderate relationships indicate **localized dependency**, not global redundancy.


---

ğŸ§  Modeling Strategy (High-Level)

Because machine failures are extremely rare, standard accuracy-focused modeling is misleading in this case.

The modeling roadmap is therefore:
	1.	Baseline Logistic Regression
			- Establish interpretable reference performance
			- Reveal class-imbalance challenges
	2.	Imbalance-Aware Training
			- Improve recall for rare failures
			- Optimize meaningful metrics (ROC-AUC, PR-AUC, Recall)
	3.	Gradient Boosting Models (LightGBM / XGBoost)
			- Capture nonlinear sensor interactions
			- Improve predictive discrimination
	4.	Probability Calibration
			- Convert raw scores into true failure risk probabilities
		 	- Enable real-world decision thresholds


---

## ğŸ” Data Version Control (DVC)

- Dataset removed from Git tracking  
- Dataset tracked using DVC
- Local DVC remote storage configured
- This helps with:
    1. Experiment Reproducibility
    2. clean Git History
    3. Production-Style Data Management  

---

## ğŸš€ Upcoming Pipeline Stages

The following production stages will be implemented:

1. Data ingestion  
2. Data preprocessing  
3. Feature engineering  
4. Model training  
5. Evaluation  
6. Experiment tracking (MLflow)  
7. Deployment-ready inference pipeline  

---

## ğŸ Current Status

âœ… EDA completed  
âœ… Dataset tracked with DVC  
âœ… Local DVC Remote Configured
âœ… Baseline training pipeline implemented 
ğŸ”„ Imbalance-aware modeling in progress
â³ Gradient boosting + calibration pending
â³ Full MLOps orchestration pending
---

## ğŸ“œ License

For educational and portfolio use.
